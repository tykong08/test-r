# GazeHome Edge Device# ğŸ  GazeHome Edge Device



ì‹œì„  ì¶”ì  ê¸°ë°˜ ìŠ¤ë§ˆíŠ¸í™ˆ ì œì–´ ì‹œìŠ¤í…œì˜ Edge Device êµ¬í˜„ì²´ì…ë‹ˆë‹¤. ì‹ ì²´ì  ì¥ì• ê°€ ìˆëŠ” ì‚¬ìš©ìë¥¼ ìœ„í•œ ì ‘ê·¼ì„± ì†”ë£¨ì…˜ìœ¼ë¡œ, ì‹œì„ ê³¼ ê¹œë¹¡ì„ë§Œìœ¼ë¡œ ìŠ¤ë§ˆíŠ¸í™ˆ ë””ë°”ì´ìŠ¤ë¥¼ ì œì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.Web-based gaze tracking edge device for smart home control using eye gaze. This demo runs on Raspberry Pi or similar edge devices and provides a browser-based UI for:



## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥- **5-point gaze calibration**

- **Dwell-time based gaze clicking**

- **ì‹œì„  ì¶”ì  (Gaze Tracking)**: dlib ê¸°ë°˜ ì‹¤ì‹œê°„ ì‹œì„  ìœ„ì¹˜ ì¶”ì - **Smart device control via Gateway API**

- **ì´ì¤‘ í´ë¦­ ëª¨ë“œ**: - **AI-powered recommendations**

  - Dwell Click: ì¼ì • ì‹œê°„ ì‘ì‹œë¡œ í´ë¦­- **Real-time video feed with gaze overlay**

  - Blink Click: ì˜ë„ì ì¸ ê¹œë¹¡ì„ìœ¼ë¡œ í´ë¦­

- **ì‹œì„  ë³´ì • (Calibration)**: 5í¬ì¸íŠ¸ ë³´ì •ìœ¼ë¡œ ì •í™•ë„ í–¥ìƒ## ğŸ¯ Features

- **ì‹¤ì‹œê°„ ì›¹ UI**: WebSocket ê¸°ë°˜ ì‹¤ì‹œê°„ ì‹œì„  í¬ì¸í„° í‘œì‹œ

- **AI ì¶”ì²œ ì‹œìŠ¤í…œ**: AI ì„œë¹„ìŠ¤ì™€ ì—°ë™í•œ ìŠ¤ë§ˆíŠ¸ ì œì–´ ì¶”ì²œ### âœ… Implemented Features



## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°1. **5-Point Calibration System**

   - Top-left, top-right, center, bottom-left, bottom-right calibration points

```   - Automatic sample collection with stability filtering

edge/   - Affine transformation for accurate gaze mapping

â”œâ”€â”€ app.py                      # FastAPI ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜   - Persistent calibration storage (JSON)

â”œâ”€â”€ config.json                 # ì„¤ì • íŒŒì¼

â”œâ”€â”€ requirements.txt            # Python ì˜ì¡´ì„±2. **Gaze Tracking with Dwell-Click**

â”œâ”€â”€ core/                       # í•µì‹¬ ëª¨ë“ˆ   - Integration with existing `gaze_tracking` module

â”‚   â”œâ”€â”€ config.py              # ì„¤ì • ê´€ë¦¬   - Configurable dwell time (default 0.8s)

â”‚   â””â”€â”€ database.py            # ë°ì´í„°ë² ì´ìŠ¤ (SQLite)   - Real-time gaze pointer visualization

â”œâ”€â”€ gaze/                       # ì‹œì„  ì¶”ì  ëª¨ë“ˆ   - AOI (Area of Interest) mapping to devices

â”‚   â”œâ”€â”€ tracker.py             # GazeTracker (ë©”ì¸)

â”‚   â””â”€â”€ calibrator.py          # ì‹œì„  ë³´ì •3. **Device Control**

â”œâ”€â”€ model/                      # ML ëª¨ë¸ (ì´ì „ gaze_tracking)   - Async HTTP client for Gateway API

â”‚   â”œâ”€â”€ gaze_tracking.py       # ì‹œì„  ì¶”ì  ë¼ì´ë¸ŒëŸ¬ë¦¬   - Device list/detail/status queries

â”‚   â”œâ”€â”€ eye.py                 # ëˆˆ ê°ì§€   - Device control commands

â”‚   â”œâ”€â”€ pupil.py               # ë™ê³µ ê°ì§€   - Periodic and manual state refresh

â”‚   â””â”€â”€ calibration.py         # ë³´ì • ì•Œê³ ë¦¬ì¦˜

â”œâ”€â”€ services/                   # ì™¸ë¶€ ì„œë¹„ìŠ¤ ì—°ë™4. **AI Recommendations**

â”‚   â”œâ”€â”€ ai_service.py          # AI ì„œë¹„ìŠ¤ í´ë¼ì´ì–¸íŠ¸   - Polling-based recommendation fetching

â”‚   â””â”€â”€ device_manager.py      # ë””ë°”ì´ìŠ¤ ê´€ë¦¬   - YES/NO response handling

â”œâ”€â”€ templates/                  # HTML í…œí”Œë¦¿   - Automatic control execution on YES

â”‚   â””â”€â”€ index.html             # ë©”ì¸ UI   - Real-time popup notifications

â””â”€â”€ static/                     # ì •ì  íŒŒì¼

    â”œâ”€â”€ app.js                 # í”„ë¡ íŠ¸ì—”ë“œ ë¡œì§5. **Web UI**

    â””â”€â”€ style.css              # ìŠ¤íƒ€ì¼ì‹œíŠ¸   - FastAPI backend with WebSocket support

```   - Real-time video streaming

   - Interactive calibration interface

## ğŸš€ ë¹ ë¥¸ ì‹œì‘   - Device cards with status display

   - Recommendation popup dialogs

### 1. í™˜ê²½ ì„¤ì •

## ğŸ“‹ Prerequisites

```bash

# Conda í™˜ê²½ ìƒì„± ë° í™œì„±í™”- Python 3.8+

conda create -n gaze python=3.11- Webcam/Camera

conda activate gaze- Gateway server running (port 8001)

- AI Service running (port 8000)

# ì˜ì¡´ì„± ì„¤ì¹˜

cd edge### System Requirements

pip install -r requirements.txt

``````bash

# macOS

### 2. ì„¤ì • íŒŒì¼ ìˆ˜ì •brew install cmake



`config.json`:# Ubuntu/Debian

```jsonsudo apt-get install build-essential cmake

{sudo apt-get install libopenblas-dev liblapack-dev

    "user_uuid": "your-uuid-here",sudo apt-get install libx11-dev libgtk-3-dev

    "ai_service_url": "http://localhost:8001",

    "mock_mode": true,  // í…ŒìŠ¤íŠ¸ìš©: true, í”„ë¡œë•ì…˜: false# Raspberry Pi

    "gaze": {sudo apt-get install python3-opencv

        "dwell_time": 0.8,sudo apt-get install libatlas-base-dev

        "screen_width": 1920,```

        "screen_height": 1080,

        "camera_index": 0## ğŸš€ Quick Start

    }

}### 1. Setup

```

```bash

### 3. ì„œë²„ ì‹¤í–‰cd edge

chmod +x setup.sh

```bash./setup.sh

python app.py```

```

Or manually:

ë¸Œë¼ìš°ì €ì—ì„œ `http://localhost:8000` ì ‘ì†

```bash

## ğŸ® ì‚¬ìš© ë°©ë²•# Create virtual environment

python3 -m venv venv

### ì‹œì„  ë³´ì •source venv/bin/activate  # On Windows: venv\Scripts\activate



1. "ì‹œì„  ë³´ì • ì‹œì‘" ë²„íŠ¼ í´ë¦­# Install dependencies

2. í™”ë©´ì— ë‚˜íƒ€ë‚˜ëŠ” ë¹¨ê°„ ì ì„ ì‘ì‹œpip install -r requirements.txt

3. 5ê°œ í¬ì¸íŠ¸ Ã— 30ìƒ˜í”Œ ìˆ˜ì§‘```

4. ë³´ì • ì™„ë£Œ í›„ ìë™ìœ¼ë¡œ ì €ì¥

### 2. Download dlib Model

**ë³´ì • íŒ:**

- ì–¼êµ´ì„ í™”ë©´ ì¤‘ì•™ì— ìœ„ì¹˜Download the facial landmarks model:

- ì¶©ë¶„í•œ ì¡°ëª… í™•ë³´ (ì •ë©´ ì¡°ëª… ê¶Œì¥)

- ì¹´ë©”ë¼ì™€ 40-60cm ê±°ë¦¬ ìœ ì§€```bash

cd ../gaze_tracking/trained_models/

### í´ë¦­ ëª¨ë“œwget http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2

bunzip2 shape_predictor_68_face_landmarks.dat.bz2

#### Dwell Click (ì‘ì‹œ í´ë¦­)```

- ëŒ€ìƒì„ 0.8ì´ˆ ì´ìƒ ì‘ì‹œ

- ì§„í–‰ ìƒí™©ì´ íŒŒë€ ì›ìœ¼ë¡œ í‘œì‹œ### 3. Configure

- ì‹œê°„ ì™„ë£Œ ì‹œ ìë™ í´ë¦­

Edit `config.json`:

#### Blink Click (ê¹œë¹¡ì„ í´ë¦­)

- 0.3~1.0ì´ˆ ì‚¬ì´ì˜ ì˜ë„ì  ê¹œë¹¡ì„```json

- ìì—°ìŠ¤ëŸ¬ìš´ ê¹œë¹¡ì„ì€ ë¬´ì‹œ (< 0.3ì´ˆ){

  "user_uuid": "8f6b3c54-7b3b-4d4c-9e5d-2e8b1c1d4f99",

**ë¯¼ê°ë„ ì¡°ì •:**  "ai_service_url": "http://localhost:8001",

ë³´ì • í™”ë©´ì—ì„œ "ì‘ì‹œ ë¯¼ê°ë„" ìŠ¬ë¼ì´ë”ë¡œ ì¡°ì • ê°€ëŠ¥ (0.3~2.0ì´ˆ)  "mock_mode": false,

  "gaze": {

## ğŸ”Œ API ë¬¸ì„œ    "dwell_time": 0.8,

    "screen_width": 1920,

### REST API    "screen_height": 1080,

    "camera_index": 0

#### 1. ìƒíƒœ ì¡°íšŒ  }

```http}

GET /api/state```

```

### 4. Run

**Response:**

```json**Option 1: Mock Mode (UI testing without servers)**

{```bash

  "user_uuid": "8f6b3c54-...",# Set mock_mode: true in config.json

  "calibrated": true,python app.py

  "devices": [```

    {

      "device_id": "ac_living_room",**Option 2: Real Mode (with AI Service)**

      "name": "ê±°ì‹¤ ì—ì–´ì»¨",```bash

      "device_type": "air_conditioner",# Make sure AI Service is running first!

      "current_state": {# AI Service will communicate with Gateway

        "is_on": true,

        "temperature": 24# Start edge device

      }python app.py

    }```

  ],

  "recommendation": nullOpen browser: **http://localhost:8000**

}

```## ğŸ“– Usage Guide



#### 2. ë””ë°”ì´ìŠ¤ ì œì–´### First-Time Setup: Calibration

```http

POST /api/devices/{device_id}/control1. Click **"ì‹œì„  ë³´ì • ì‹œì‘"** button

Content-Type: application/json2. Look at each red target point for 2-3 seconds

3. The system will automatically collect samples and move to the next target

{4. After all 5 points, calibration is complete and saved

  "action": "toggle",  // or "turn_on", "turn_off", "set_temperature"5. Calibration persists across sessions in `calibration_params.json`

  "parameters": {      // ì„ íƒì 

    "temperature": 24### Controlling Devices

  }

}**Method 1: Gaze Click (Primary)**

```1. Look at a device card

2. Hold your gaze steady for ~0.8 seconds

#### 3. ì‹œì„  ë³´ì •3. A dwell indicator will grow around your gaze point

4. Click is triggered automatically

**ë³´ì • ì‹œì‘:**5. AI service analyzes intent and shows recommendation

```http6. Choose YES or NO

POST /api/calibration/start

```**Method 2: Manual Click (Fallback)**

- Click on device cards with mouse/touch

**ìƒ˜í”Œ ì¶”ê°€:**

```http### Viewing Device Status

POST /api/calibration/sample

```- Device cards show real-time status

- Green indicator = ON

**ë‹¤ìŒ íƒ€ê²Ÿìœ¼ë¡œ ì´ë™:**- Gray indicator = OFF

```http- Cards update automatically every 5 seconds

POST /api/calibration/next

```### AI Recommendations



**ì§„í–‰ ìƒí™© ì¡°íšŒ:**When you gaze-click a device:

```http1. AI analyzes your intent based on:

GET /api/calibration/progress   - Device current state

```   - Time of day

   - Weather (via MCP)

**Response:**   - Historical patterns

```json2. Shows recommendation popup

{3. Click YES to execute or NO to dismiss

  "is_complete": false,

  "current_target": 0,## ğŸ—ï¸ Architecture

  "total_targets": 5,

  "current_samples": 15,```

  "required_samples": 30,edge/

  "target_position": [960, 540]â”œâ”€â”€ app.py                 # Main FastAPI server

}â”œâ”€â”€ config.json           # Configuration

```â”œâ”€â”€ requirements.txt      # Python dependencies

â”œâ”€â”€ setup.sh             # Setup script

#### 4. ì‘ì‹œ ì‹œê°„ ì„¤ì •â”œâ”€â”€ test_edge.py         # Test suite

```httpâ”‚

POST /api/dwell-timeâ”œâ”€â”€ core/

Content-Type: application/jsonâ”‚   â”œâ”€â”€ __init__.py

â”‚   â””â”€â”€ config.py        # Configuration manager

{â”‚

  "dwell_time": 0.8â”œâ”€â”€ gaze/

}â”‚   â”œâ”€â”€ __init__.py

```â”‚   â”œâ”€â”€ calibrator.py    # 5-point calibration

â”‚   â””â”€â”€ tracker.py       # Gaze tracking + dwell-click

### WebSocket APIâ”‚

â”œâ”€â”€ api/

```javascriptâ”‚   â”œâ”€â”€ __init__.py

const ws = new WebSocket('ws://localhost:8000/ws');â”‚   â”œâ”€â”€ gateway_client.py   # Gateway API client

â”‚   â””â”€â”€ ai_client.py        # AI Service API client

ws.onmessage = (event) => {â”‚

  const data = JSON.parse(event.data);â”œâ”€â”€ templates/

  â”‚   â””â”€â”€ index.html          # Main web UI

  switch(data.type) {â”‚

    case 'gaze':â””â”€â”€ static/

      // ì‹œì„  ìœ„ì¹˜ ì—…ë°ì´íŠ¸    â”œâ”€â”€ style.css          # Styles

      console.log(data.position); // {x: 960, y: 540}    â””â”€â”€ app.js             # Frontend JavaScript

      break;```

      

    case 'click':## ğŸ”Œ API Integration

      // í´ë¦­ ì´ë²¤íŠ¸

      console.log(data.device_id);### Gateway API (Port 8001)

      console.log(data.method); // 'dwell' or 'blink'

      break;**Get Devices**

      ```http

    case 'dwell':GET /v1/devices

      // Dwell ì§„í–‰ë„```

      console.log(data.progress); // 0.0 ~ 1.0

      break;**Control Device**

      ```http

    case 'state':POST /v1/devices/{device_id}/control

      // ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸Content-Type: application/json

      console.log(data.devices);

      break;{

  }  "user_uuid": "8f6b3c54-7b3b-4d4c-9e5d-2e8b1c1d4f99",

};  "action": "toggle",

```  "parameters": {}

}

## ğŸ¤– AI ì„œë¹„ìŠ¤ ì—°ë™```



### AI Service API### AI Service API (Port 8000)



Edge DeviceëŠ” ë³„ë„ì˜ AI Serviceì™€ í†µì‹ í•©ë‹ˆë‹¤:**Send Device Click**

```http

**ì¶”ì²œ ìš”ì²­:**POST /api/gaze/click

```httpContent-Type: application/json

POST http://localhost:8001/api/recommendations

Content-Type: application/json{

  "user_id": "8f6b3c54-7b3b-4d4c-9e5d-2e8b1c1d4f99",

{  "session_id": "session_123",

  "user_uuid": "8f6b3c54-...",  "clicked_device": {

  "context": {    "device_id": "ac_01",

    "time": "2024-01-01T14:30:00",    "device_type": "air_conditioner",

    "devices": [...]    "device_name": "ê±°ì‹¤ ì—ì–´ì»¨",

  }    "display_name": "ì—ì–´ì»¨",

}    "capabilities": ["on_off", "temperature"],

```    "current_state": {"is_on": false, "temperature": 24}

  }

**ë””ë°”ì´ìŠ¤ ì œì–´ ì „ì†¡:**}

```http```

POST http://localhost:8001/api/device-control

Content-Type: application/json**Poll Recommendations**

```http

{GET /v1/intent?user_uuid=8f6b3c54-7b3b-4d4c-9e5d-2e8b1c1d4f99

  "user_uuid": "8f6b3c54-...",```

  "device_id": "ac_living_room",

  "action": "turn_on",**Respond to Recommendation**

  "method": "gaze_blink"```http

}POST /v1/intent

```Content-Type: application/json



## ğŸŒ‰ Gateway ì—°ë™{

  "user_uuid": "8f6b3c54-7b3b-4d4c-9e5d-2e8b1c1d4f99",

Gatewayì™€ì˜ í†µì‹ ì€ AI Serviceë¥¼ í†µí•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤:  "recommendation_id": "rec_123",

  "answer": "YES"

```}

Edge Device -> AI Service -> Gateway -> Smart Device```

```

## âš™ï¸ Configuration Reference

**Mock ëª¨ë“œ:**

- `mock_mode: true`: ê°€ìƒ ë””ë°”ì´ìŠ¤ë¡œ í…ŒìŠ¤íŠ¸| Parameter                         | Description                               | Default                                  |

- `mock_mode: false`: ì‹¤ì œ Gateway ì—°ë™| --------------------------------- | ----------------------------------------- | ---------------------------------------- |

| `user_uuid`                       | Single user identifier for all operations | `"8f6b3c54-7b3b-4d4c-9e5d-2e8b1c1d4f99"` |

## ğŸ–¥ï¸ UI êµ¬ì„±| `ai_service_url`                  | AI service URL                            | `"http://localhost:8001"`                |

| `mock_mode`                       | Enable mock mode for UI testing           | `false`                                  |

### ë©”ì¸ í™”ë©´| `gaze.dwell_time`                 | Dwell time for click (seconds)            | `0.8`                                    |

| `gaze.screen_width`               | Screen width (pixels)                     | `1920`                                   |

- **í—¤ë”**: ë³´ì • ìƒíƒœ, ì—°ê²° ìƒíƒœ| `gaze.screen_height`              | Screen height (pixels)                    | `1080`                                   |

- **ì‹œì„  í¬ì¸í„°**: ì „ì²´ í™”ë©´ì— ë…¹ìƒ‰ í¬ì¸í„° í‘œì‹œ| `gaze.camera_index`               | Camera device index                       | `0`                                      |

- **Dwell ì§„í–‰ë„**: ì‘ì‹œ ì¤‘ì¸ ëŒ€ìƒì— íŒŒë€ ì› í‘œì‹œ| `polling.device_status_interval`  | Device status refresh interval (seconds)  | `5.0`                                    |

- **ì œì–´ íŒ¨ë„**: ë³´ì • ì‹œì‘, ê¸°ê¸° ìƒˆë¡œê³ ì¹¨| `polling.recommendation_interval` | Recommendation poll interval (seconds)    | `3.0`                                    |

- **ë””ë°”ì´ìŠ¤ ê·¸ë¦¬ë“œ**: ì—°ê²°ëœ ìŠ¤ë§ˆíŠ¸ ë””ë°”ì´ìŠ¤ ì¹´ë“œ

## ğŸ§ª Testing

### ë³´ì • í™”ë©´

**Unit Tests:**

- **íƒ€ê²Ÿ í¬ì¸íŠ¸**: ë¹¨ê°„ ì  (5ê°œ ìœ„ì¹˜)```bash

- **ì›¹ìº  í”„ë¦¬ë·°**: ìš°ì¸¡ í•˜ë‹¨ì— ì–¼êµ´ í™•ì¸ìš©python test_edge.py

- **ì§„í–‰ ë°”**: í˜„ì¬ í¬ì¸íŠ¸ ë° ìƒ˜í”Œ ìˆ˜```

- **ë¯¼ê°ë„ ì¡°ì •**: ì‘ì‹œ ì‹œê°„ ìŠ¬ë¼ì´ë”

**Mock Mode UI Testing:**

## ğŸ”§ ë¬¸ì œ í•´ê²°See [MOCK_MODE_TESTING.md](./MOCK_MODE_TESTING.md) or [QUICK_START_MOCK.md](./QUICK_START_MOCK.md)



### ì¹´ë©”ë¼ê°€ ì—´ë¦¬ì§€ ì•ŠìŒTests include:

```bash- Configuration loading

# ì¹´ë©”ë¼ ì¸ë±ìŠ¤ í™•ì¸- Calibration system

python -c "import cv2; print([i for i in range(5) if cv2.VideoCapture(i).isOpened()])"- API client connectivity

- Gateway health check

# config.jsonì—ì„œ camera_index ìˆ˜ì •- AI service health check

```

## ğŸ› Troubleshooting

### ë™ê³µ ê°ì§€ ì•ˆ ë¨ (pupils_detected=False)

- ì¡°ëª…ì„ ë°ê²Œ ì¡°ì •### Camera not detected

- ì–¼êµ´ì„ í™”ë©´ ì •ë©´ì— ìœ„ì¹˜```bash

- ì¹´ë©”ë¼ì™€ì˜ ê±°ë¦¬ ì¡°ì • (40-60cm)# List available cameras

- ì•ˆê²½ì´ ë¹›ì„ ë°˜ì‚¬í•˜ëŠ” ê²½ìš° ê°ë„ ì¡°ì •ls /dev/video*



### WebSocket ì—°ê²° ëŠê¹€# Test camera

```bashpython -c "import cv2; print(cv2.VideoCapture(0).isOpened())"

# uvicorn[standard] ì¬ì„¤ì¹˜```

pip install --upgrade 'uvicorn[standard]'

```### dlib installation fails

```bash

### import ì˜¤ë¥˜# macOS

```bashbrew install cmake

# ê²½ë¡œ í™•ì¸pip install dlib

echo $PYTHONPATH

# Ubuntu

# í™˜ê²½ ì¬ì„¤ì •sudo apt-get install cmake libboost-all-dev

cd edgepip install dlib

export PYTHONPATH="${PYTHONPATH}:$(pwd)"```

python app.py

```### Gateway/AI Service not responding

- Check servers are running: `http://localhost:8001/health`, `http://localhost:8000/health`

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”- Verify URLs in `config.json`

- Check firewall settings

### í”„ë ˆì„ ë ˆì´íŠ¸

- ê¶Œì¥: 30 FPS### Calibration inaccurate

- configì—ì„œ ì¡°ì • ê°€ëŠ¥- Ensure good lighting

- ë‚®ì€ ì‚¬ì–‘ì—ì„œëŠ” 15 FPSë¡œ ê°ì†Œ- Keep head still during calibration

- Recalibrate if needed (click "ì‹œì„  ë³´ì • ì‹œì‘" again)

### ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰- Adjust `stability_threshold` in `gaze/calibrator.py`

- ê¸°ë³¸: ~500MB

- dlib ëª¨ë¸ ë¡œë”©: ~100MB## ğŸ“Š Performance Optimization

- ì›¹ìº  ë²„í¼: ~50MB

### For Raspberry Pi

## ğŸ”’ ë³´ì•ˆ

1. **Reduce video resolution**

- HTTPS ì§€ì› (í”„ë¡œë•ì…˜ í™˜ê²½)```python

- UUID ê¸°ë°˜ ì‚¬ìš©ì ì¸ì¦# In app.py, before camera.read()

- AI Serviceì™€ í† í° ê¸°ë°˜ í†µì‹ camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)

camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)

## ğŸ“ ë¡œê·¸```



ë¡œê·¸ ë ˆë²¨ ì„¤ì •:2. **Increase polling intervals**

```python```json

# app.py{

logging.basicConfig(level=logging.INFO)  # DEBUG, INFO, WARNING, ERROR  "polling": {

```    "device_status_interval": 10.0,

    "recommendation_interval": 5.0

ì£¼ìš” ë¡œê·¸:  }

- `Camera Status: OPEN` - ì¹´ë©”ë¼ ì •ìƒ ì‘ë™}

- `Gaze result: position=(x, y), pupils_detected=True` - ì‹œì„  ì¶”ì  ì„±ê³µ```

- `Blink click detected: 0.45s` - ê¹œë¹¡ì„ í´ë¦­ ê°ì§€

- `Click detected (dwell): device_id at (x, y)` - ì‘ì‹œ í´ë¦­ ê°ì§€3. **Use hardware acceleration** (if available)

```bash

## ğŸ§ª í…ŒìŠ¤íŠ¸# Enable OpenCL for Raspberry Pi

sudo apt-get install ocl-icd-libopencl1

### ë¸Œëœì¹˜ë³„ ëª¨ë“œ```



- **main**: í”„ë¡œë•ì…˜ ëª¨ë“œ (`mock_mode: false`)## ğŸ”’ Security Considerations

- **test**: ê°œë°œ/í…ŒìŠ¤íŠ¸ ëª¨ë“œ (`mock_mode: true`)

âš ï¸ **This is a demo implementation**

```bash

# í…ŒìŠ¤íŠ¸ ë¸Œëœì¹˜ë¡œ ì „í™˜For production:

git checkout test- Add authentication (JWT tokens)

- Use HTTPS for API calls

# í”„ë¡œë•ì…˜ ë¸Œëœì¹˜ë¡œ ì „í™˜- Encrypt calibration data

git checkout main- Implement rate limiting

```- Add CORS restrictions

- Secure WebSocket connections

## ğŸ¤ ê¸°ì—¬

## ğŸ“ Data Flow

ì´ìŠˆ ë° Pull Request í™˜ì˜í•©ë‹ˆë‹¤!

```

## ğŸ“„ ë¼ì´ì„ ìŠ¤1. Camera â†’ Gaze Tracking â†’ Calibration Transform â†’ Screen Coordinates

2. Screen Coordinates â†’ Dwell Detection â†’ Click Event

ì´ í”„ë¡œì íŠ¸ëŠ” ì ‘ê·¼ì„± í–¥ìƒì„ ëª©í‘œë¡œ ê°œë°œë˜ì—ˆìŠµë‹ˆë‹¤.3. Click Event â†’ AOI Mapping â†’ Device ID + Action

4. Device Info â†’ AI Service â†’ Intent Analysis â†’ Recommendation

## ğŸ“ ë¬¸ì˜5. Recommendation â†’ User (YES/NO) â†’ AI Service Response

6. YES â†’ Gateway Control â†’ Device State Update â†’ UI Refresh

ë¬¸ì œê°€ ë°œìƒí•˜ë©´ GitHub Issuesì— ë“±ë¡í•´ì£¼ì„¸ìš”.```



---## ğŸ“ Future Enhancements



**ê°œë°œ í™˜ê²½:**- [ ] WebSocket for real-time recommendations (replace polling)

- Python 3.11- [ ] Multi-user support with face recognition

- FastAPI 0.104- [ ] Voice confirmation for recommendations

- OpenCV 4.8- [ ] Gesture-based commands (blink, nod)

- dlib 19.24- [ ] Offline mode with cached recommendations

- WebSocket (uvicorn[standard])- [ ] Progressive Web App (PWA) for mobile

- [ ] Analytics dashboard

**í…ŒìŠ¤íŠ¸ í™˜ê²½:**- [ ] Custom AOI editor

- macOS / Raspberry Pi OS

- ì›¹ìº : ë‚´ì¥ ì¹´ë©”ë¼ or USB ì¹´ë©”ë¼## ğŸ“„ License

- ë¸Œë¼ìš°ì €: Chrome, Firefox, Safari (ìµœì‹  ë²„ì „)

See main project LICENSE file.

## ğŸ™ Credits

- **GazeTracking**: Base gaze tracking library
- **dlib**: Facial landmark detection
- **FastAPI**: Web framework
- **OpenCV**: Computer vision

---

**Built with â¤ï¸ for GazeHome Project**
